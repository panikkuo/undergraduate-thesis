{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f714376-39cd-45f5-a5e7-d65923a1db9d",
   "metadata": {},
   "source": [
    "### Собственно что это?\n",
    "\n",
    "Как говорится не сломаешь не поймешь: используя знания от безусловной генерации я хочу попробовать придумать условную генерацию по метке но только уже свою"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ae9453-87e4-4f09-9e8e-3d6af95f062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kagglehub\n",
    "import idx2numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6119bd-5a38-4771-9f49-d34e1c9261c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist():\n",
    "    path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n",
    "    print(\"Путь до данных:\", path)\n",
    "\n",
    "    train_images_path = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "    train_labels_path = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    test_imaages_path = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "    test_labels_path = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    \n",
    "    X_train = idx2numpy.convert_from_file(train_images_path)\n",
    "    y_train = idx2numpy.convert_from_file(train_labels_path)\n",
    "    X_test = idx2numpy.convert_from_file(test_imaages_path)\n",
    "    y_test = idx2numpy.convert_from_file(test_labels_path)\n",
    "\n",
    "    print(f'Загружено тренировочных картинток: {len(X_train)}')\n",
    "    print(f'Загружено тренировочных меток: {len(y_train)}')\n",
    "    print(f'Загружено тестовых картинток: {len(X_test)}')\n",
    "    print(f'Загружено тестовых меток: {len(y_test)}')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3031719-20c9-4dd2-b4d3-77133d882569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь до данных: C:\\Users\\panika\\.cache\\kagglehub\\datasets\\hojjatk\\mnist-dataset\\versions\\1\n",
      "Загружено тренировочных картинток: 60000\n",
      "Загружено тренировочных меток: 60000\n",
      "Загружено тестовых картинток: 10000\n",
      "Загружено тестовых меток: 10000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = read_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c986cd5-70e2-4fb5-9a29-1f18608133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X):\n",
    "    X_zero_one = X / 255.0\n",
    "    X_minus_one_one = (X_zero_one - 0.5) * 2.0\n",
    "    return X_minus_one_one\n",
    "\n",
    "batch_size = 128\n",
    "X = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_norm = normalize_data(X)\n",
    "X_batch = X_norm.view(-1, 1, 28, 28)\n",
    "train_loader = DataLoader(TensorDataset(X_batch), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196ced54-98e9-45aa-8ecc-75c09deac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "alphas = 1 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e4fa40-0429-43ad-80b0-43205d5bb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample(x_start, t, alphas_cumprod, noise):  \n",
    "    \"\"\"\n",
    "    Add noise to x_start\n",
    "    Args:\n",
    "        x_start: [Batch, canals, W, H]\n",
    "        t: [B,]\n",
    "        alphas_cumprod: array of alphas\n",
    "        noise: [Batch, canals, W, H] ~ N(0, I)\n",
    "    \"\"\"\n",
    "    sqrt_alphas_cumprod_t = torch.sqrt(alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1 - alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
    "\n",
    "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "def time_embedding(t, dim):\n",
    "    \"\"\"\n",
    "    n = dim\n",
    "    t -> {sin(w1*t), cos(w1*t), ... sin(wn*t), cos(wn*t)}\n",
    "    Args:\n",
    "        t: [B, ]\n",
    "        dim: scalar\n",
    "    \"\"\"\n",
    "    idx = torch.arange(0, dim // 2, device=t.device)\n",
    "    w = 1 / (10000 ** ((2 * idx) / dim))\n",
    "    angles = t[:, None] * w[None, :]\n",
    "    sin = torch.sin(angles)\n",
    "    cos = torch.cos(angles)\n",
    "    return torch.cat([sin, cos], dim=-1)\n",
    "\n",
    "\n",
    "def label_embedding(x, dim):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b84a5-34c8-4751-829e-1800ecd2e6ef",
   "metadata": {},
   "source": [
    "### Собственно какие идеи у меня?\n",
    "\n",
    "Мне очень нравится идеи с тем, что аддитивно добавляя время картинка перемещается в свою область. Очевидно, я буду отображать метку в какой то вектор, а после добавлять также аддитивно (хотя можно и мультипликативно), но есть мысль, что если два раза пройтись ReLu(Conv(Relu(Conv(x)) + t)), то может быть проблема того, что информация просто потеряется и хотелось бы научиться это делать параллельно\n",
    "\n",
    "Пусть f: t $\\rightarrow$ v отображение времени в вектор. Есть крутая идея того, что все векторы при t $\\in$ [0, 1000] f(t) не образует полноценный базис и метку отобразить в ортогональное дополнение и передвигать в тэтом направлении но это слишком сложно\n",
    "\n",
    "### Идея 1\n",
    "\n",
    "Можно попробовать просто добавить один слой\n",
    "\n",
    "y - метка\n",
    "\n",
    "h = ReLU(Conv(x)) \\\n",
    "h = ReLU(Conv(h + y)) \\\n",
    "h = ReLU(Conv(h + t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee17bdee-cee7-47d1-8eb4-cfd961dc6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet1(nn.Module):\n",
    "    class Block(nn.Module):\n",
    "        def __init__(self, in_ch, out_ch, v_dim):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.conv3 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.mlp = nn.Linear(v_dim, out_ch)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x, time_embedding, label_embedding):\n",
    "            v1 = self.mlp(label_embedding).view(time_embedding.shape[0], -1, 1, 1)\n",
    "            v2 = self.mlp(time_embedding).view(time_embedding.shape[0], -1, 1, 1)\n",
    "            \n",
    "            h = self.relu(self.conv1(x))\n",
    "            h = self.relu(self.conv2(h + v1))\n",
    "            h = self.relu(self.conv3(h + v2))\n",
    "\n",
    "            if x.shape[1] == h.shape[1]:\n",
    "                return x + h\n",
    "            return h\n",
    "\n",
    "    def __init__(self, v_dim):\n",
    "        super().__init__()\n",
    "        self.v_dim = v_dim\n",
    "        self.init_conv = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.down1 = Unet1.Block(64, 64, v_dim)\n",
    "        self.to_128 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.down2 = Unet1.Block(128, 128, v_dim)\n",
    "        self.to_256 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.bottleneck = Unet1.Block(256, 256, v_dim)\n",
    "        \n",
    "        self.up_to_14 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.up_block1 = Unet1.Block(384, 128, v_dim)\n",
    "\n",
    "        self.up_to_28 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.up_block2 = Unet1.Block(192, 64, v_dim)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        t_emb = time_embedding(t, self.v_dim)\n",
    "        y_emb = label_embedding(y, self.v_dim)\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        s1 = self.down1(x, t_emb, y_emb)\n",
    "        x = self.to_128(s1)\n",
    "\n",
    "        s2 = self.down2(x, t_emb, y_emb)\n",
    "        x = self.to_256(s2)\n",
    "\n",
    "        x = self.bottleneck(x, t_emb, y_emb)\n",
    "\n",
    "        x = self.up_to_14(x)\n",
    "        x = torch.cat([x, s2], dim=1)\n",
    "        x = self.up_block1(x, t_emb, y_emb)\n",
    "\n",
    "        x = self.up_to_28(x)\n",
    "        x = torch.cat([x, s1], dim=1)\n",
    "        x = self.up_block2(x, t_emb, y_emb)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ff66ab0-965c-4c1b-bafc-6f46cfdfc24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3 s\n",
      "Wall time: 5.15 s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdevice = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m if torch.cuda.is_available() else \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtime_dim=128\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mmodel = Unet1(time_dim).to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43moptimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mepochs = 20\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43malphas_cumprod_tensor = alphas_cumprod.to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfor epoch in range(epochs):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    model.train()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    epoch_loss = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for batch in train_loader:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        x0 = batch[0].to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t = torch.randint(0, timesteps, (x0.shape[0],), device=device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        real_noise = torch.randn_like(x0).to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        xt = q_sample(x0, t, alphas_cumprod_tensor, real_noise)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        predicted_noise = model(xt, t, y)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        loss = torch.nn.functional.mse_loss(predicted_noise, real_noise)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        optimizer.zero_grad()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        loss.backward()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        optimizer.step()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        epoch_loss += loss.item()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    torch.cuda.synchronize()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(f\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mЭпоха \u001b[39;49m\u001b[38;5;132;43;01m{epoch}\u001b[39;49;00m\u001b[33;43m: Loss MSE: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mepoch_loss / len(train_loader)}\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\MPEI\\Диплом\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\MPEI\\Диплом\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\MPEI\\Диплом\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:20\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "time_dim=128\n",
    "model = Unet1(time_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "alphas_cumprod_tensor = alphas_cumprod.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x0 = batch[0].to(device)\n",
    "        t = torch.randint(0, timesteps, (x0.shape[0],), device=device)\n",
    "        real_noise = torch.randn_like(x0).to(device)\n",
    "        \n",
    "        xt = q_sample(x0, t, alphas_cumprod_tensor, real_noise)\n",
    "\n",
    "        predicted_noise = model(xt, t, )\n",
    "        loss = torch.nn.functional.mse_loss(predicted_noise, real_noise)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f'Эпоха {epoch}: Loss MSE: {epoch_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b504bd-5ec7-4350-ad82-c6c726780e1d",
   "metadata": {},
   "source": [
    "### Идея 2\n",
    "\n",
    "Изначально функция f является отображнием f: t $\\rightarrow$ v. Можно представить это как отображение от 2 скаляров f: (y, t) $\\rightarrow$ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130e136-4889-4ea1-8036-06db0b327061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet2(nn.Module):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
